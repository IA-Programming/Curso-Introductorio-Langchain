{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeVQXsQdzku08/e9y7YrFX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IA-Programming/Curso-Introductorio-Langchain/blob/main/conceptos/lab/l3_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando las librerías necesarias"
      ],
      "metadata": {
        "id": "jFMUZAWtnxEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "id": "_JG-C8WpiuzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9c6944-0bc0-47fc-a8ba-78a5d0106cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.0.2.post1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.11)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.23.5)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.8.0)\n",
            "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain_openai)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (0.0.81)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (0.26.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain_openai) (2023.6.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain_openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.7->langchain_openai) (2.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain_openai) (2.0.7)\n",
            "Installing collected packages: tiktoken, langchain_openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain_openai-0.0.2.post1 tiktoken-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpXOFmKYAEJQ",
        "outputId": "3dc72b91-363e-47e0-d66f-1cd5b186d324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain-openai\n",
            "Version: 0.0.2.post1\n",
            "Summary: An integration package connecting OpenAI and LangChain\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: langchain-core, numpy, openai, tiktoken\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estableciendo las variables de entorno"
      ],
      "metadata": {
        "id": "bCTbx9uyocdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "qRKfzj98og7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c03400bf-5bb8-48c2-a69c-630f876cbb58"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI Modelo"
      ],
      "metadata": {
        "id": "hbde4NyIpBr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=0.5)\n",
        "\n",
        "response = llm('helllo, how are you?')\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Dq9qOEOVpHZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "560ca225-22ef-417d-b80a-5f886c73a795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Hello! I am an AI language model created by OpenAI. I do not have emotions or feelings, but I am functioning well. How can I assist you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the asynchronous iterator to retrieve the streaming output\n",
        "for chunk in llm.stream(\"Write me a song about sparkling water.\"):\n",
        "    print(chunk, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5w8gZOzOtQg",
        "outputId": "d0690ef4-9070-47d3-af44-3cc0d2874bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Verse 1:\n",
            "Bubbles dancing in my glass\n",
            "Crystal clear, it's such a blast\n",
            "Refreshing taste, it's like a dream\n",
            "Sparkling water, you're my new favorite thing\n",
            "\n",
            "Chorus:\n",
            "Oh sparkling water, you're my delight\n",
            "Fizzing up, so light and bright\n",
            "You quench my thirst, you make me smile\n",
            "With every sip, I feel so alive\n",
            "\n",
            "Verse 2:\n",
            "No sugar, no calories\n",
            "Just pure goodness, it's plain to see\n",
            "A healthier choice, I'm glad I found\n",
            "Sparkling water, you're my go-to drink now\n",
            "\n",
            "Chorus:\n",
            "Oh sparkling water, you're my delight\n",
            "Fizzing up, so light and bright\n",
            "You quench my thirst, you make me smile\n",
            "With every sip, I feel so alive\n",
            "\n",
            "Bridge:\n",
            "Some may say you're just plain water\n",
            "But to me, you're so much more\n",
            "You bring a sparkle to my day\n",
            "In every sip, I taste your allure\n",
            "\n",
            "Chorus:\n",
            "Oh sparkling water, you're my delight\n",
            "Fizzing up, so light and bright\n",
            "You quench my thirst, you make me smile\n",
            "With every sip, I feel so alive\n",
            "\n",
            "Outro:\n",
            "So here's to you, my sparkling friend"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass a list of inputs to the abatch method\n",
        "inputs = [\n",
        "    \"What is the capital of France?\",\n",
        "    \"Who wrote the book 'To Kill a Mockingbird'?\",\n",
        "    \"What is the square root of 64?\"\n",
        "]\n",
        "results = llm.batch(inputs)\n",
        "\n",
        "# Process the results\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHrnDlYANFep",
        "outputId": "5b71e2f2-ebfd-492b-a691-1a1e1773480e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of France is Paris.\n",
            "\n",
            "\n",
            "Harper Lee.\n",
            "\n",
            "\n",
            "The square root of 64 is 8.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatOpenAI Modelo"
      ],
      "metadata": {
        "id": "wko83SX7pMdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=0.5)\n",
        "\n",
        "response = chat.invoke('hello, how are you?')\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "tPA35YQrpRJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6456ec81-985f-4fab-831c-6c6b99a6423c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the asynchronous iterator to retrieve the streaming output\n",
        "for chunk in chat.stream(\"Hello, how are you?\"):\n",
        "    print(chunk.content, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVhagXdma12C",
        "outputId": "50d20105-5c50-4717-a6f8-2ce6754897e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm just a language model AI, so I don't have feelings, but I'm here to help you. How can I assist you today?"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a list of messages or prompts\n",
        "inputs = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"What is the weather like today?\",\n",
        "    \"Tell me a joke.\"\n",
        "]\n",
        "\n",
        "# Use the batch method for batch processing\n",
        "outputs = chat.batch(inputs)\n",
        "\n",
        "# Process the outputs\n",
        "for output in outputs:\n",
        "    print(output.content)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_s_mcPdf8uK",
        "outputId": "3b4323ae-bd28-4d8b-f647-63b0cf621e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here to help you. How can I assist you today?\n",
            "\n",
            "I'm sorry, but I cannot provide real-time weather information. I suggest checking a reliable weather website or app for the current weather conditions in your area.\n",
            "\n",
            "Why don't skeletons fight each other?\n",
            "\n",
            "They don't have the guts!\n",
            "\n"
          ]
        }
      ]
    }
  ]
}