{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+JCXjr/fPZhRjsbGn76pk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IA-Programming/Curso-Introductorio-Langchain/blob/main/conceptos/lab/l9-chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando las librer铆as necesarias"
      ],
      "metadata": {
        "id": "ZYizwyYsDWy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIaTnI6wCvAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0c4324-89d9-4b93-b242-15a02b391ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m222.3/222.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m218.9/218.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain openai langchain_openai streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurando el entorno de trabajo"
      ],
      "metadata": {
        "id": "4DIGFGz0DoJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "YTIZm4KODyCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e892e38-2b49-49af-af71-85ed4a4d712e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: 路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot Proyecto"
      ],
      "metadata": {
        "id": "jKx7NIUg7k9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import os\n",
        "import streamlit as st\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.schema import HumanMessage, AIMessage\n",
        "\n",
        "# App title\n",
        "st.set_page_config(page_title=\"ChatGPT CLI\", page_icon=\"\")\n",
        "\n",
        "st.title(' Langchain ChatGPT CLI')\n",
        "\n",
        "# Function for generating LLM response\n",
        "def Chatbot():\n",
        "    # Create ChatBot\n",
        "    llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), temperature=0.0)\n",
        "    return ConversationChain(llm=llm,memory=st.session_state.messages)\n",
        "\n",
        "# Store LLM generated responses\n",
        "if \"messages\" not in st.session_state.keys():\n",
        "    st.session_state['messages'] = ConversationBufferMemory()\n",
        "    st.session_state.messages.chat_memory.messages.append(AIMessage(content= \"Como puedo ayudarte?\"))\n",
        "if \"chatbot\" not in st.session_state.keys():\n",
        "    st.session_state['chatbot'] = Chatbot()\n",
        "\n",
        "# Display chat messages\n",
        "for message in st.session_state.messages.buffer_as_messages:\n",
        "    st.chat_message(message.type).write(message.content)\n",
        "\n",
        "# User-provided prompt\n",
        "# Generate a new response if last message is not from assistant\n",
        "if prompt := st.chat_input(disabled=True if 'OPENAI_API_KEY' not in os.environ else False):\n",
        "    st.chat_message(\"human\").write(prompt)\n",
        "    with st.chat_message(\"ai\"):\n",
        "        with st.spinner(\"Pensando...\"):\n",
        "            response = st.session_state.chatbot.predict(input= prompt)\n",
        "            st.write(response)"
      ],
      "metadata": {
        "id": "JcXQQElaHWhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa35aa9f-f72c-400d-d00e-0f32efbbb5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running a Streamlit app\n"
      ],
      "metadata": {
        "id": "F-496hceO8np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run streamlit_app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "TVTNjw7zO73K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipv4.icanhazip.com\n",
        "!echo \"Copy this IP into the webpage that opens below\""
      ],
      "metadata": {
        "id": "j5Onpw20PB5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53cdadcf-7ab9-4ecf-b304-1dc92f07eed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.186.182.230\n",
            "Copy this IP into the webpage that opens below\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "USrGjay5PFAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e8b3e6-51dc-4d04-841a-ec7c52f4fd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.407s\n",
            "your url is: https://stupid-taxes-shine.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}