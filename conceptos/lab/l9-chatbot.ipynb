{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsAgu3EqVP2OJJTw0/CT5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IA-Programming/Curso-Introductorio-Langchain/blob/main/conceptos/lab/l9-chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando las librerías necesarias"
      ],
      "metadata": {
        "id": "ZYizwyYsDWy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIaTnI6wCvAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0103fa-287a-407a-ddc6-2035cd228b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.0/237.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain openai langchain_openai langchain_community streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurando el entorno de trabajo"
      ],
      "metadata": {
        "id": "4DIGFGz0DoJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "YTIZm4KODyCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57edde5-5f0e-4776-fcdf-6becfc39efc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI()\n",
        "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
        "chain = prompt | model\n",
        "\n",
        "for s in chain.stream({\"topic\": \"bears\"}):\n",
        "  time.sleep(2)\n",
        "  print(s.content, end=\"\", flush=True)"
      ],
      "metadata": {
        "id": "6ji0cvs5cY_I",
        "outputId": "78c79ab7-af9c-44cc-8ed5-2438138ced7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why don't bears wear shoes?\n",
            "\n",
            "Because they have bear feet!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot Proyecto"
      ],
      "metadata": {
        "id": "jKx7NIUg7k9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import os, time\n",
        "import streamlit as st\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "# App title\n",
        "st.set_page_config(page_title=\"ChatGPT CLI\", page_icon=\"🤖\")\n",
        "\n",
        "st.title('🤖 Langchain ChatGPT CLI')\n",
        "\n",
        "# MEMORY\n",
        "if 'messages' not in st.session_state:\n",
        "  st.session_state['messages'] = []\n",
        "  st.session_state.messages.append(SystemMessage(content=\"Soy ChatGPT, tu asistente virtual. Como puedo ayudarte?\"))\n",
        "  st.session_state.messages.append(AIMessage(content=\"En que puedo ayudarte el dia de hoy?\"))\n",
        "\n",
        "# # Store LLM generated responses\n",
        "if \"chatbot\" not in st.session_state.keys():\n",
        "    st.session_state['chatbot'] = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), temperature=0, streaming=True)\n",
        "\n",
        "# Display chat messages\n",
        "for msg in st.session_state.messages:\n",
        "  if msg.type == \"human\" or msg.type == \"ai\":\n",
        "    st.chat_message(msg.type).write(msg.content)\n",
        "\n",
        "# Generate a new response if last message is not from assistant\n",
        "if prompt := st.chat_input(disabled=True if 'OPENAI_API_KEY' not in os.environ else False):\n",
        "    st.chat_message(\"human\").write(prompt)\n",
        "    full_response = \"\"\n",
        "    st.session_state.messages.append(HumanMessage(content=prompt))\n",
        "    with st.chat_message(\"ai\"):\n",
        "      message_placeholder = st.empty()\n",
        "      with st.spinner(\"Pensando...\"):\n",
        "        for chunk in st.session_state.chatbot._stream(messages=st.session_state.messages):\n",
        "          full_response += chunk.message.content\n",
        "          message_placeholder.markdown(full_response + \"▌\")\n",
        "          time.sleep(0.5)\n",
        "          message_placeholder.markdown(full_response)\n",
        "        st.session_state.messages.append(AIMessage(content=full_response))"
      ],
      "metadata": {
        "id": "xdXj40NE1aA2",
        "outputId": "93121efc-9702-49ea-b683-a8e5a853d673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running a Streamlit app\n"
      ],
      "metadata": {
        "id": "F-496hceO8np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run streamlit_app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "TVTNjw7zO73K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipv4.icanhazip.com\n",
        "!echo \"Copy this IP into the webpage that opens below\""
      ],
      "metadata": {
        "id": "j5Onpw20PB5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c1bb26-5cd6-4d5f-fda1-20e6a13ce6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.133.137.216\n",
            "Copy this IP into the webpage that opens below\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "USrGjay5PFAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d9233f-a5f6-4fa2-a3d3-7c0c4116c19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.097s\n",
            "your url is: https://sour-planes-eat.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}